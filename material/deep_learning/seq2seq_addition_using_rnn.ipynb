{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq_addition_using_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOJ1rebQqJ-p"
      },
      "source": [
        "# eq2seq 학습을 사용한 숫자 덧셈\n",
        "\n",
        "\n",
        "**작성자:** [임도형](http://github.com/dhrim)<br>\n",
        "**원 작성자:** [Smerity](https://twitter.com/Smerity)와 다른이들<br>\n",
        "**원 문서:** https://keras.io/examples/nlp/addition_rnn/<br>\n",
        "**작성일:** 2020/08/22<br>\n",
        "**최종 수정일:** 2020/08/22<br>\n",
        "**개요:** 숫자 덧셈 문자열의 입력으로 값 문자열을 구한다. 예 \"535+61\" -> \"596\"<br>\n",
        "**원 개요:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\".\n",
        "\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Qgsg_W497m"
      },
      "source": [
        "# 소개\n",
        "\n",
        "본 예는 2개의 숫자를 더한 값을 문자열로 출력하는 모델을 학습시킨다.\n",
        "\n",
        "**예:**\n",
        "- 입력 : \"535+61\"\n",
        "- 출력 : \"506\"\n",
        "\n",
        "다음과 같은 다양한 작업에서 보여지듯이 성능을 위해 입력은 선택적으로 연순이 될 수 있다. [Learning to Execute](http://arxiv.org/abs/1410.4615), \n",
        "[Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
        "\n",
        "이론적으로 순차열 역순은 이런 문제에서 입력과 출력 간에 더 의존성을 더 짧게 한다.\n",
        "\n",
        "**결과**:<br>\n",
        "2자리(역순):<br>\n",
        "- 1 LSTM층(128 유닛), 5K 학습 데이터 = 55 에폭후에 99% 학습/평가 정확도\n",
        "\n",
        "3자리(역순):<br>\n",
        "- 1 LSTM층(128 유닛), 50K 학습 데이터 = 100 에폭후에 99% 학습/평가 정확도\n",
        "\n",
        "4자리(역순):<br>\n",
        "- 1 LSTM층(128 유닛), 400K 학습 데이터 = 20 에폭후에 99% 학습/평가 정확도\n",
        "\n",
        "5자리(역순):<br>\n",
        "- 1 LSTM층(128 유닛), 128K 학습 데이터 = 30 에폭후에 99% 학습/평가 정확도 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ux6UDaa493R"
      },
      "source": [
        "\n",
        "# 예제 설명\n",
        "\n",
        "# Seq2Seq 학습\n",
        "\n",
        "순차열(sequence)를 입력으로 순차열(sequence)를 출력하는 모델 학습.\n",
        "\n",
        "보통 인코더 + 디코더의 구조입니다. 인코더는 입력 문자열을 처리하여 문맥(context)를 출력하고 디코더는 이 문맥을 디코딩하여 목적하는 출력을 내도록 학습합니다.\n",
        "\n",
        "\n",
        "참고 : https://wikidocs.net/24996\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "## 학습 내용\n",
        "\n",
        "다음과 같은 입력문자열에 대하여 출력문자열을 타겟으로 학습한다.\n",
        "\n",
        "```\n",
        "입력문자열 --->  출력문자열\n",
        "'18+7   '  --->  '25  '\n",
        "'583+2  '  --->  '585 '\n",
        "'58+12  '  --->  '70  '\n",
        "'5+85   '  --->  '90  '\n",
        "```\n",
        "\n",
        "결과적으로 입력된 문자열에 대한 덧셈을 수행하는 관계를 학습한다.\n",
        "\n",
        "<br>\n",
        "\n",
        "## 역순 입력\n",
        "\n",
        "성능을 위해서 엽력 문자열을 역순으로 해서 사용한다.\n",
        "\n",
        "```\n",
        "입력문자열 --->  출력문자열\n",
        "'   7+81'  --->  '25  '\n",
        "'  2+385'  --->  '585 '\n",
        "'  21+85'  --->  '70  '\n",
        "'   58+5'  --->  '90  '\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "## 데이터\n",
        "\n",
        "### 입출력 데이터의 길이\n",
        "숫자의 최대 길이(DIGIT)가 3이면 2개의 숫자와 덧셈기호의 최대 길이는 7이다. 출력은 최대 4(3자리 숫자의 합은 최대 4자리)이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### one-hot 인코딩\n",
        "실제 학습에 사용되는 데이터는 각 문자열이 one-hot 인코딩된 값이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### 입력 데이터 모양\n",
        "입력 문자열의 길이는 7이고 각 문자는 12개 길이로 one-hot 인코딩된다.\n",
        "\n",
        "사용되는 문자는 0~9까지 숫자 10개와 덧셈기호와 스페이스 해서 총 12개이다. 입력 문자열의 길이는 7이고 1개의 문자는 길이 12의 one-hot 인코딩된 값이라서 1개 데이터의 모양은 (7,12)이다.\n",
        "\n",
        "입력 문자열이 ' 13+528'이라면 실제 학습에 사용되는 입력값은 다음과 같다.\n",
        "```\n",
        "[[1 0 0 0 0 0 0 0 0 0 0 0]    <--- ' '\n",
        " [0 0 0 1 0 0 0 0 0 0 0 0]    <--- '1'\n",
        " [0 0 0 0 0 1 0 0 0 0 0 0]    <--- '3'\n",
        " [0 1 0 0 0 0 0 0 0 0 0 0]    <--- '+'\n",
        " [0 0 0 0 0 0 0 1 0 0 0 0]    <--- '5'    \n",
        " [0 0 0 0 1 0 0 0 0 0 0 0]    <--- '2'\n",
        " [0 0 0 0 0 0 0 0 0 0 1 0]]   <--- '8'\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "### 출력 데이터 모양\n",
        "출력 문자열이 '856 '이라면 실제 학습에 사용되는 출력값은 다음과 같다.\n",
        "\n",
        "```        \n",
        "[[0 0 0 0 0 0 0 0 0 0 1 0]    <--- '8'\n",
        " [0 0 0 0 0 0 0 1 0 0 0 0]    <--- '5'\n",
        " [0 0 0 0 0 0 0 0 1 0 0 0]    <--- '6'\n",
        " [1 0 0 0 0 0 0 0 0 0 0 0]]   <--- ' '     \n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "## 모델\n",
        "\n",
        "### 모델 입출력\n",
        "입력 모양은 (7,12)이고 출력 모양은 (4,12)이다.\n",
        "\n",
        "7은 입력문자열의 최대 길이, 4는 출력문자열의 최대 길이, 그리고 12는 입출력에 사용되는 문자의 갯수가 12라서 one-hot 인코딩된 값의 길이이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "### Question-Answer 모델\n",
        "\n",
        "Question-Answer 구조의 모델이다. 질문 무자열이 입력되고 이를 encoder가 인코딩한다. 그리고 그 값을 다시  디코더가 decoding해서 답을 구한다.\n",
        "\n",
        "2개의 LSTM이 각각 인코더, 디코더로 사용된다.\n",
        "\n",
        "<br>\n",
        "\n",
        "다음 구조의 모델을 사용한다.\n",
        "```\n",
        "model = keras.Sequential()\n",
        "model.add(LSTM(..., input_shape=(MAXLEN, 12)) # encoder\n",
        "model.add(RepeatVector(DIGIT+1))\n",
        "model.add(LSTM(..., return_sequences=True)) # decoder\n",
        "model.add(Dense(12, activation=\"softmax\"))\n",
        "```\n",
        "2개의 LSTM이 있고 첫번째가 인코더이고, 두번째가 디코더이다.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "출력층 Dense의 노드 수가 12개 인것은 12개의 문자중에 1개를 선택하기 위한 것이다. 그래서 activation이 softmax이고.\n",
        "\n",
        "전체 모델의 출력은 one-hot 인코딩된 4개의 자리값이어야 한다. 이를 위해 4개의 타임 스텝이 필요하다. 이를 위해 디코더 LSTM앞에 RepeatedVector(4)가 있어서 인코딩된 128 차원의 값을 4번 반복한다.\n",
        "\n",
        "결과적으로 디코더 LSTM은 4개의 값을 출력하고 Dense는 각각 4개의 값에 대한 문자열을 softmax로 출력한다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou-ygxNfo-Ec"
      },
      "source": [
        "## 셋업\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5OvBIiWo-Ec"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "TRAINING_SIZE = 50000   # 학습 데이터의 갯수\n",
        "DIGITS = 3              # 덧셈에 사용될 숫자 자리수\n",
        "REVERSE = True          # 입력 문자열의 역순 여부. \n",
        "\n",
        "# 입력 문자열의 최대 길이.\n",
        "# 숫자 2개의 길이 에 '+' 길이 1을 더한 값이다.\n",
        "# 숫자 자리수가 3이면 예를 들어 '345+678'과 같이 최대 길이는 7이다.\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dQt0G10o-Eg"
      },
      "source": [
        "## Generate the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COsdmY5vo-Eg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc170003-3fb2-4386-bc9e-7e82d0f28005"
      },
      "source": [
        "# 사용될 문자들. 0~9까지 숫자 10개와 덧셈 '+'와 스페이스 ' '\n",
        "chars = \"0123456789+ \"\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "\n",
        "    # 임의의 숫자를 만드는 함수\n",
        "    # step1. 최대 자리수를 임의로 선택하고. 최소 1, 최대 3(DIGIT). 선택된 것이 3이라면\n",
        "    # step2. 각 자리의 숫자를 선택하고. '1', '3', '5'\n",
        "    # step3. 각 자리의 숫자를 붙여서 문자열 만들고. '135'\n",
        "    # step4. 만든 문자열을 int로 변환. '135' -> 135\n",
        "    f = lambda: int( # step4\n",
        "        \"\".join( # step3\n",
        "            np.random.choice(list(\"0123456789\")) # step2\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))  # step1\n",
        "        )\n",
        "    )\n",
        "    # 2개의 숫자를 선택했다.\n",
        "    a, b = f(), f()\n",
        "    # a = 123\n",
        "    # b = 45\n",
        "\n",
        "    # 이미 만들었던 문제면 다시 만들자.\n",
        "    # x+y와 y+x의 중복도 체크하기 위해 소팅해서 체크한다.\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "\n",
        "    # 문제 문자열을 만들자\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    # q = '123+45'\n",
        "\n",
        "    # 문자열 길이가 MAXLEN이 되도록 스페이스를 뒤에 붙인다.\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    # query = '123+45 '\n",
        "\n",
        "    # 정답 문자열을 구한다.\n",
        "    ans = str(a + b)\n",
        "    # ans = '168'\n",
        "\n",
        "    # 정답은 최대 DIGITS + 1 길이이다. 최대 길이가 되도록 스페이스를 앞에 붙인다.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    # ans = ' 168'\n",
        "\n",
        "    # 역순으로 처리한다면\n",
        "    # 문제 문자열을 역순으로 한다.\n",
        "    if REVERSE:\n",
        "        # '123+45  '가 '  54+321'가 된다.\n",
        "        query = query[::-1]\n",
        "        # query = ' 54+321'\n",
        "\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "\n",
        "print(\"Total questions:\", len(questions))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmLHQod8nlcU",
        "outputId": "aee23c53-080a-433a-b538-71cbbdc52f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(questions[:5])\n",
        "print(expected[:5])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[' 592+45', '  6+112', '   3+32', '  18+71', ' 78+747']\n",
            "['349 ', '217 ', '26  ', '98  ', '834 ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7eFX6jIyrnx"
      },
      "source": [
        "# 데이터를 벡터화 하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jO8skDb7p3f"
      },
      "source": [
        "인코딩 디코딩을 위한 유틸 클래스 CharacterTable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sqn4LUtHyi46"
      },
      "source": [
        "class CharacterTable:\n",
        "    \"\"\" 특정 문자열 집합을 가지고:\n",
        "    + one-hot 인코딩\n",
        "    + one-hot된 혹은 숫자로 인코딩된 값을 원 무자열로 디코딩\n",
        "    + softmax 같은 확율 벡터를 원 문자열로 디코딩\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"문자 테이블을 초기화\n",
        "        # Arguments\n",
        "            chars: 입력에 사용되는 문자들\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        # self.char_indices = { ' ': 0, \n",
        "        #                       '+': 1,\n",
        "        #                       '0': 2, \n",
        "        #                       '1': 3, \n",
        "        #                       ...\n",
        "        #                       '9': 11}\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "        # self.indices_char = { 0: ' ', \n",
        "        #                       1: '+', \n",
        "        #                       2: '0', \n",
        "        #                       3: '1', \n",
        "        #                       ...\n",
        "        #                       11: '9'}\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"전달된 문자열 C를 One-hot 인코딩 한다.\n",
        "        # Arguments\n",
        "            C: 인코딩할 문자열. 예 ' 123+45'\n",
        "            num_rows: 반환될 행 수. 입력 길이와 관계없이 반환되는 행 수를 동일하기 위해 사용된다.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C): # 각 자리 문자마다\n",
        "            x[i, self.char_indices[c]] = 1 # 각 줄의 index만 1로 만든다. one-hot encoding한다.\n",
        "\n",
        "        # 반환되는 x는 num_rows의 행이고, 각 행은 각 문자에 대한 one-hot 인코딩된 값이다.\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"전달된 벡터값 혹은 2D 배열을 해당 문자열로 디코딩한다.\n",
        "        # Arguments\n",
        "            x: 벡터 혹은 one-hot 인코딩된 2D 배열 혹은 softmax된 확률 2D 배열 \n",
        "               혹은 calc_argmax=False일 때는 문자 인덱스 벡터\n",
        "            calc_argmax: 최대 값의 index 값을 찾을 지 여부. default는 True.\n",
        "        \"\"\"\n",
        "\n",
        "        # one-hot 인코딩 혹은 softmax 값이면 최대 index를 구한다.\n",
        "        if calc_argmax:\n",
        "            # x = [ [0 0 0 0 1 0 0 0 0 0 0 0]\n",
        "            #       [0 0 0 0 0 1 0 0 0 0 0 0]\n",
        "            #       [0 0 0 0 0 0 1 0 0 0 0 0]]\n",
        "            x = x.argmax(axis=-1)\n",
        "            # x = [ 4 5 6 ]\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVYzei1I7XZb"
      },
      "source": [
        "ctable = CharacterTable(chars)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_fJZA7b7Y-e"
      },
      "source": [
        "다음은 인코딩, 디코딩 예이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwm40AA-r4tt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fa9d5e-d289-424b-fbe1-d02583c275a0"
      },
      "source": [
        "# 원 문자열\n",
        "org_str = ' 123+45'\n",
        "print(f\"org_str='{org_str}'\")\n",
        "\n",
        "# 인코딩된 값\n",
        "encoded = ctable.encode(org_str, MAXLEN)\n",
        "# [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]      <--- ' '\n",
        "#  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]      <--- '1'\n",
        "#  [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]      <--- '2'\n",
        "#  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]      <--- '3'\n",
        "#  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]      <--- '+'\n",
        "#  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]      <--- '4'\n",
        "#  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]     <--- '5'\n",
        "print(f\"encoded=\\n{encoded}\")\n",
        "print(f\"encoded.shape={encoded.shape}\")\n",
        "\n",
        "# 다시 디코딩해서 원복한 값\n",
        "decoded = ctable.decode(encoded)\n",
        "print(f\"decoded='{decoded}'\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "org_str=' 123+45'\n",
            "encoded=\n",
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
            "encoded.shape=(7, 12)\n",
            "decoded=' 123+45'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1QHj3MDo-Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa2ad90e-9a65-4c1d-ad3c-d8038ce7a6fd"
      },
      "source": [
        "print(\"Vectorization...\")\n",
        "\n",
        "# DIGITS = 3\n",
        "# MAXLEN = DIGITS + 1 + DIGITS\n",
        "# chars = '0123456789+'\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "# x 데이터 한개의 모양은 (7, 12)  # 7 글자, 12개 글자 종류(0~9, '+', ' ')\n",
        "# y 데이터 한개의 모양은 (3, 12)  # 3 글자, 12개 글자 종류(0~9, '+', ' ')\n",
        "\n",
        "# x의 뒷쪽은 대부분 큰 자리수의 문제이다.\n",
        "# 이를 커버하기 위해 섞는다.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# 명시적으로 10%는 학습에 사용되지 않는 validation 데이터로 딸 둔다.\n",
        "# 역자주 : 보통 데이터는 train/validation/test로 분리합니다. \n",
        "# 학습 시에 사용하지 않는 것은 test 데이터인데 저자가 혼동한 듯 합니다.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(train_x, x_val) = x[:split_at], x[split_at:]\n",
        "(train_y, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectorization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  import sys\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMq2Om3w8qNy"
      },
      "source": [
        "준비된 데이터는 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41UcKyn-q5Ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ce8aad-256b-4b8b-b81a-7ec893216b35"
      },
      "source": [
        "print(\"train_x[0]\\n\", train_x[0].astype(np.int16))\n",
        "print()\n",
        "print(\"train_y[0]\\n\", train_y[0].astype(np.int16))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x[0]\n",
            " [[1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0 0 0 0]]\n",
            "\n",
            "train_y[0]\n",
            " [[0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa-gM3Nq84XK"
      },
      "source": [
        "준비된 데이터는 인코딩된 값들입니다. 디코딩에서 본 원 문자열은 다음과 같습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw_RFfJvrGFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329f779e-e804-463b-81e4-5e93f2bf10ca"
      },
      "source": [
        "for i in range(10):\n",
        "  print(\"'\"+ctable.decode(train_x[i])+\"' -> '\"+ctable.decode(train_y[i])+\"'\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' 801+41' -> '122 '\n",
            "' 12+774' -> '498 '\n",
            "'058+851' -> '1008'\n",
            "' 62+471' -> '200 '\n",
            "' 609+12' -> '927 '\n",
            "' 94+709' -> '956 '\n",
            "'  0+621' -> '126 '\n",
            "'  55+04' -> '95  '\n",
            "'  167+2' -> '763 '\n",
            "' 887+15' -> '839 '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MkDWbri9EAd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2liXf2Yo-En"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP8Vw2aNtzPn"
      },
      "source": [
        "# 모델 정의\n",
        "\n",
        "LSTM을 사용. 모델은 다음과 같다.\n",
        "\n",
        "```\n",
        "model.add(layers.LSTM(..., input_shape=(7, 12)) # 7:입력 최대 길이, 12:문자 종류 수\n",
        "model.add(RepeatVector(4)) # 4:숫자 최대길이 3+1. 4자리가 되도록 값을 반복한다.\n",
        "model.add(LSTM(..., return_sequences=True)\n",
        "model.add(Dense(12, activation=\"softmax\")) # 12:문자 종류 수\n",
        "```\n",
        "\n",
        "각 층의 출력은 다음과 같다.\n",
        "```\n",
        "LSTM            (None, 128)\n",
        "RepeatVector    (None, 4, 128)    # [1,2] -> [ [1,2], [1,2], [1,2], [1,2] ]\n",
        "LSTM            (None, 4, 128)\n",
        "Dense           (None, 4, 12)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFO2GZHdos1e"
      },
      "source": [
        "```\n",
        "model = keras.Sequential()\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "model.add(layers.LSTM(128, return_sequences=True))\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "\n",
        "\n",
        "lstm (LSTM)                  (None, 128)               72192     \n",
        "repeat_vector (RepeatVector) (None, 4, 128)            0         \n",
        "lstm_1 (LSTM)                (None, 4, 128)            131584    \n",
        "dense (Dense)                (None, 4, 12)             1548      \n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUr-sqkoo-En",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01902134-10e9-4640-e83b-beca03a1e747"
      },
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# 입력 순차열을 LSTM을 사용하여 128길이의 출력으로 인코딩한다.\n",
        "# 주의 : 입력 길이가 변하는 상황이면 input_shape=(None, num_feature)로 한다.\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "\n",
        "# 디코더 입력으로 인코딩된 값을 각 시간 스텝(출력 자리) 수 만큼 반복해 준다.\n",
        "# 출력 최대 길이인 DIGIT+1만큼 반복한다. \n",
        "# DIGIT가 3일때 최대 출력값은 999+999=1998이다.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "\n",
        "# 디코더 RNN은 한 층 혹은 여러층일 수 있다.\n",
        "for _ in range(num_layers):\n",
        "    # return_sequences을 True로 놓아 마지막 스텝뿐 아니라 전체 스텝의 출력값을 \n",
        "    # (num_samples, timesteps, output_dimc) 모양으로 출력한다.\n",
        "    # 이것은 다음 층에서 사용되는 TimeDistributed가 입력의 첫 차원이 시간 스텝이어야 하기 때문이다.\n",
        "    #\n",
        "    # 역자주 : TensorFlow 2.0이전에는 model.add(TimeDistributed(Dense(..)))의 형태로 쓰여야 했다.\n",
        "    # 주석에서 TimeDistributed에 관련된 것은 아마도 코드를 업데이트 하면서 주석은 업데이트 하지 않은 것 같다.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# 각 스텝의 출력에 대한 문자열을 선택하도록 한다.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4, 12)             1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5L-7r5Yo-Er"
      },
      "source": [
        "## 모델 학습\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-Zav9Fro-Er",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923475d6-b986-474a-b772-f15cc7bc017b"
      },
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# 학습을 실행하고, 각 학습 중에 validation 데이터에 대한 결과를 보여준다.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "\n",
        "    # 10개 랜덤 샘플을 골라 결과를 보여준다.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        # rowx = [[[1 0 0 0 0 0 0 0 0 0 0 0]    <--- ' '\n",
        "        #          [0 0 0 1 0 0 0 0 0 0 0 0]    <--- '1'\n",
        "        #          [0 0 0 0 0 1 0 0 0 0 0 0]    <--- '3'\n",
        "        #          [0 1 0 0 0 0 0 0 0 0 0 0]    <--- '+'\n",
        "        #          [0 0 0 0 0 0 0 1 0 0 0 0]    <--- '5'    \n",
        "        #          [0 0 0 0 1 0 0 0 0 0 0 0]    <--- '2'\n",
        "        #          [0 0 0 0 0 0 0 0 0 0 1 0]]]  <--- '8'\n",
        "        #                                            ' 13+528'\n",
        "        #\n",
        "        # rowy = [[[0 0 0 0 0 0 0 0 0 0 1 0]    <--- '8'\n",
        "        #          [0 0 0 0 0 0 0 1 0 0 0 0]    <--- '5'\n",
        "        #          [0 0 0 0 0 0 0 0 1 0 0 0]    <--- '6'\n",
        "        #          [1 0 0 0 0 0 0 0 0 0 0 0]]]  <--- ' '     \n",
        "        #                                            '856 '   \n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        # preds = [[10  7  8  0]]\n",
        "        # 요 preds 값은 CharacterTable에 정의된 indices_char의 키 값에 해당한다.\n",
        "        #   {0: ' ',   # <------\n",
        "        #    1: '+', \n",
        "        #    ...\n",
        "        #    7: '5'    # <------\n",
        "        #    8: '6'    # <------\n",
        "        #    9: '7'\n",
        "        #    10: '8'   # <------\n",
        "        #    11: '9'}        \n",
        "\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        #  q       = ' 13+528'  <--- '825+31 '가 reverse된 것.\n",
        "        #  correct = '856 '\n",
        "        #  guess   = '856 '        \n",
        "        \n",
        "        # REVERSE = True\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        # Q 825+31\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        # T 856  \n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)\n",
        "        # ☑ 856             \n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 17s 6ms/step - loss: 1.7656 - accuracy: 0.3531 - val_loss: 1.5935 - val_accuracy: 0.4086\n",
            "Q 211+623 T 834  ☒ 802 \n",
            "Q 777+819 T 1596 ☒ 1237\n",
            "Q 246+82  T 328  ☒ 399 \n",
            "Q 88+239  T 327  ☒ 339 \n",
            "Q 18+23   T 41   ☒ 20  \n",
            "Q 586+16  T 602  ☒ 659 \n",
            "Q 633+8   T 641  ☒ 435 \n",
            "Q 999+12  T 1011 ☒ 902 \n",
            "Q 456+615 T 1071 ☒ 102 \n",
            "Q 64+258  T 322  ☒ 359 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.3817 - accuracy: 0.4831 - val_loss: 1.1912 - val_accuracy: 0.5638\n",
            "Q 64+314  T 378  ☒ 399 \n",
            "Q 178+66  T 244  ☒ 222 \n",
            "Q 0+455   T 455  ☒ 459 \n",
            "Q 89+146  T 235  ☒ 202 \n",
            "Q 8+511   T 519  ☒ 520 \n",
            "Q 12+17   T 29   ☒ 24  \n",
            "Q 43+655  T 698  ☒ 692 \n",
            "Q 74+255  T 329  ☒ 212 \n",
            "Q 886+663 T 1549 ☒ 1511\n",
            "Q 541+57  T 598  ☒ 512 \n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 1.0625 - accuracy: 0.6064 - val_loss: 0.9602 - val_accuracy: 0.6411\n",
            "Q 882+333 T 1215 ☒ 1111\n",
            "Q 82+392  T 474  ☒ 473 \n",
            "Q 6+495   T 501  ☒ 403 \n",
            "Q 94+17   T 111  ☒ 118 \n",
            "Q 567+2   T 569  ☒ 565 \n",
            "Q 670+82  T 752  ☒ 763 \n",
            "Q 764+1   T 765  ☒ 766 \n",
            "Q 52+405  T 457  ☒ 458 \n",
            "Q 416+466 T 882  ☒ 788 \n",
            "Q 878+1   T 879  ☒ 888 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.8695 - accuracy: 0.6788 - val_loss: 0.8037 - val_accuracy: 0.7073\n",
            "Q 520+0   T 520  ☒ 525 \n",
            "Q 14+150  T 164  ☒ 162 \n",
            "Q 295+12  T 307  ☒ 302 \n",
            "Q 506+43  T 549  ☒ 550 \n",
            "Q 133+96  T 229  ☒ 222 \n",
            "Q 729+52  T 781  ☒ 785 \n",
            "Q 81+938  T 1019 ☒ 1022\n",
            "Q 543+20  T 563  ☒ 566 \n",
            "Q 892+843 T 1735 ☑ 1735\n",
            "Q 53+63   T 116  ☒ 115 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.7622 - accuracy: 0.7205 - val_loss: 0.7282 - val_accuracy: 0.7303\n",
            "Q 748+991 T 1739 ☒ 1736\n",
            "Q 430+7   T 437  ☒ 438 \n",
            "Q 205+560 T 765  ☒ 758 \n",
            "Q 507+560 T 1067 ☒ 1066\n",
            "Q 100+51  T 151  ☒ 154 \n",
            "Q 987+5   T 992  ☑ 992 \n",
            "Q 3+3     T 6    ☒ 4   \n",
            "Q 8+715   T 723  ☒ 721 \n",
            "Q 38+94   T 132  ☒ 121 \n",
            "Q 814+9   T 823  ☒ 822 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.6419 - accuracy: 0.7654 - val_loss: 0.5293 - val_accuracy: 0.8109\n",
            "Q 205+786 T 991  ☒ 999 \n",
            "Q 892+305 T 1197 ☒ 1299\n",
            "Q 37+47   T 84   ☒ 83  \n",
            "Q 81+938  T 1019 ☑ 1019\n",
            "Q 5+863   T 868  ☑ 868 \n",
            "Q 183+21  T 204  ☑ 204 \n",
            "Q 99+605  T 704  ☒ 604 \n",
            "Q 286+135 T 421  ☒ 422 \n",
            "Q 72+513  T 585  ☑ 585 \n",
            "Q 788+9   T 797  ☑ 797 \n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.3855 - accuracy: 0.8690 - val_loss: 0.2855 - val_accuracy: 0.9100\n",
            "Q 11+530  T 541  ☒ 542 \n",
            "Q 445+35  T 480  ☑ 480 \n",
            "Q 233+925 T 1158 ☑ 1158\n",
            "Q 909+92  T 1001 ☑ 1001\n",
            "Q 87+551  T 638  ☑ 638 \n",
            "Q 907+20  T 927  ☒ 928 \n",
            "Q 72+391  T 463  ☒ 464 \n",
            "Q 917+288 T 1205 ☑ 1205\n",
            "Q 8+464   T 472  ☑ 472 \n",
            "Q 4+609   T 613  ☑ 613 \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.2263 - accuracy: 0.9358 - val_loss: 0.2250 - val_accuracy: 0.9254\n",
            "Q 940+725 T 1665 ☑ 1665\n",
            "Q 998+14  T 1012 ☑ 1012\n",
            "Q 200+15  T 215  ☒ 216 \n",
            "Q 8+128   T 136  ☑ 136 \n",
            "Q 2+553   T 555  ☑ 555 \n",
            "Q 647+38  T 685  ☑ 685 \n",
            "Q 584+2   T 586  ☑ 586 \n",
            "Q 669+450 T 1119 ☑ 1119\n",
            "Q 55+667  T 722  ☑ 722 \n",
            "Q 474+331 T 805  ☑ 805 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1478 - accuracy: 0.9610 - val_loss: 0.1430 - val_accuracy: 0.9578\n",
            "Q 621+88  T 709  ☑ 709 \n",
            "Q 24+968  T 992  ☑ 992 \n",
            "Q 566+856 T 1422 ☑ 1422\n",
            "Q 659+62  T 721  ☑ 721 \n",
            "Q 67+279  T 346  ☑ 346 \n",
            "Q 6+228   T 234  ☒ 233 \n",
            "Q 6+456   T 462  ☑ 462 \n",
            "Q 856+46  T 902  ☑ 902 \n",
            "Q 651+65  T 716  ☑ 716 \n",
            "Q 850+510 T 1360 ☒ 1361\n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.1073 - accuracy: 0.9722 - val_loss: 0.1416 - val_accuracy: 0.9573\n",
            "Q 5+659   T 664  ☑ 664 \n",
            "Q 387+277 T 664  ☒ 765 \n",
            "Q 56+839  T 895  ☑ 895 \n",
            "Q 31+534  T 565  ☑ 565 \n",
            "Q 42+592  T 634  ☑ 634 \n",
            "Q 761+85  T 846  ☑ 846 \n",
            "Q 505+442 T 947  ☒ 847 \n",
            "Q 12+359  T 371  ☑ 371 \n",
            "Q 199+35  T 234  ☑ 234 \n",
            "Q 395+874 T 1269 ☑ 1269\n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0836 - accuracy: 0.9788 - val_loss: 0.0906 - val_accuracy: 0.9735\n",
            "Q 242+333 T 575  ☑ 575 \n",
            "Q 125+689 T 814  ☑ 814 \n",
            "Q 1+870   T 871  ☑ 871 \n",
            "Q 515+49  T 564  ☑ 564 \n",
            "Q 245+52  T 297  ☑ 297 \n",
            "Q 190+971 T 1161 ☒ 1160\n",
            "Q 26+261  T 287  ☑ 287 \n",
            "Q 833+89  T 922  ☑ 922 \n",
            "Q 297+5   T 302  ☑ 302 \n",
            "Q 5+736   T 741  ☑ 741 \n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0589 - accuracy: 0.9862 - val_loss: 0.0763 - val_accuracy: 0.9783\n",
            "Q 85+80   T 165  ☑ 165 \n",
            "Q 714+4   T 718  ☑ 718 \n",
            "Q 920+907 T 1827 ☒ 1837\n",
            "Q 775+2   T 777  ☑ 777 \n",
            "Q 622+107 T 729  ☑ 729 \n",
            "Q 86+140  T 226  ☑ 226 \n",
            "Q 870+91  T 961  ☑ 961 \n",
            "Q 46+945  T 991  ☑ 991 \n",
            "Q 885+402 T 1287 ☑ 1287\n",
            "Q 699+79  T 778  ☑ 778 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0525 - accuracy: 0.9866 - val_loss: 0.0647 - val_accuracy: 0.9804\n",
            "Q 11+165  T 176  ☑ 176 \n",
            "Q 95+113  T 208  ☑ 208 \n",
            "Q 6+503   T 509  ☒ 519 \n",
            "Q 267+249 T 516  ☑ 516 \n",
            "Q 224+71  T 295  ☑ 295 \n",
            "Q 61+917  T 978  ☑ 978 \n",
            "Q 198+517 T 715  ☑ 715 \n",
            "Q 35+894  T 929  ☑ 929 \n",
            "Q 971+20  T 991  ☒ 9901\n",
            "Q 904+85  T 989  ☑ 989 \n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0442 - accuracy: 0.9884 - val_loss: 0.0850 - val_accuracy: 0.9732\n",
            "Q 223+895 T 1118 ☑ 1118\n",
            "Q 34+485  T 519  ☑ 519 \n",
            "Q 933+256 T 1189 ☑ 1189\n",
            "Q 633+69  T 702  ☑ 702 \n",
            "Q 760+9   T 769  ☑ 769 \n",
            "Q 91+18   T 109  ☑ 109 \n",
            "Q 87+807  T 894  ☑ 894 \n",
            "Q 49+731  T 780  ☑ 780 \n",
            "Q 86+318  T 404  ☑ 404 \n",
            "Q 18+722  T 740  ☑ 740 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0364 - accuracy: 0.9912 - val_loss: 0.3108 - val_accuracy: 0.9184\n",
            "Q 152+3   T 155  ☑ 155 \n",
            "Q 982+99  T 1081 ☒ 1071\n",
            "Q 73+2    T 75   ☒ 74  \n",
            "Q 833+115 T 948  ☑ 948 \n",
            "Q 806+47  T 853  ☑ 853 \n",
            "Q 590+94  T 684  ☑ 684 \n",
            "Q 4+788   T 792  ☑ 792 \n",
            "Q 921+999 T 1920 ☒ 1830\n",
            "Q 95+522  T 617  ☑ 617 \n",
            "Q 153+45  T 198  ☑ 198 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0423 - accuracy: 0.9888 - val_loss: 0.0164 - val_accuracy: 0.9970\n",
            "Q 49+416  T 465  ☑ 465 \n",
            "Q 42+592  T 634  ☑ 634 \n",
            "Q 391+18  T 409  ☑ 409 \n",
            "Q 804+14  T 818  ☑ 818 \n",
            "Q 977+40  T 1017 ☑ 1017\n",
            "Q 0+125   T 125  ☑ 125 \n",
            "Q 4+177   T 181  ☑ 181 \n",
            "Q 16+115  T 131  ☑ 131 \n",
            "Q 227+81  T 308  ☑ 308 \n",
            "Q 89+710  T 799  ☑ 799 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0434 - accuracy: 0.9872 - val_loss: 0.0198 - val_accuracy: 0.9959\n",
            "Q 49+600  T 649  ☑ 649 \n",
            "Q 815+37  T 852  ☑ 852 \n",
            "Q 74+619  T 693  ☑ 693 \n",
            "Q 157+31  T 188  ☑ 188 \n",
            "Q 2+203   T 205  ☑ 205 \n",
            "Q 53+133  T 186  ☑ 186 \n",
            "Q 46+25   T 71   ☑ 71  \n",
            "Q 933+81  T 1014 ☑ 1014\n",
            "Q 460+4   T 464  ☑ 464 \n",
            "Q 905+14  T 919  ☑ 919 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 0.0520 - val_accuracy: 0.9828\n",
            "Q 436+39  T 475  ☑ 475 \n",
            "Q 906+17  T 923  ☑ 923 \n",
            "Q 917+68  T 985  ☑ 985 \n",
            "Q 977+5   T 982  ☑ 982 \n",
            "Q 830+575 T 1405 ☑ 1405\n",
            "Q 710+557 T 1267 ☑ 1267\n",
            "Q 6+400   T 406  ☑ 406 \n",
            "Q 908+2   T 910  ☑ 910 \n",
            "Q 7+979   T 986  ☑ 986 \n",
            "Q 622+107 T 729  ☑ 729 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0239 - accuracy: 0.9944 - val_loss: 0.0148 - val_accuracy: 0.9965\n",
            "Q 653+32  T 685  ☑ 685 \n",
            "Q 362+32  T 394  ☑ 394 \n",
            "Q 9+915   T 924  ☑ 924 \n",
            "Q 162+35  T 197  ☑ 197 \n",
            "Q 20+328  T 348  ☑ 348 \n",
            "Q 925+8   T 933  ☑ 933 \n",
            "Q 44+423  T 467  ☑ 467 \n",
            "Q 72+383  T 455  ☑ 455 \n",
            "Q 801+216 T 1017 ☑ 1017\n",
            "Q 513+80  T 593  ☑ 593 \n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0264 - accuracy: 0.9927 - val_loss: 0.0152 - val_accuracy: 0.9962\n",
            "Q 159+336 T 495  ☑ 495 \n",
            "Q 61+58   T 119  ☑ 119 \n",
            "Q 47+589  T 636  ☑ 636 \n",
            "Q 86+89   T 175  ☑ 175 \n",
            "Q 51+674  T 725  ☑ 725 \n",
            "Q 90+879  T 969  ☑ 969 \n",
            "Q 106+122 T 228  ☑ 228 \n",
            "Q 751+6   T 757  ☑ 757 \n",
            "Q 16+242  T 258  ☑ 258 \n",
            "Q 2+860   T 862  ☑ 862 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0131 - accuracy: 0.9973 - val_loss: 0.0122 - val_accuracy: 0.9972\n",
            "Q 920+41  T 961  ☑ 961 \n",
            "Q 20+78   T 98   ☑ 98  \n",
            "Q 25+452  T 477  ☑ 477 \n",
            "Q 59+441  T 500  ☑ 500 \n",
            "Q 919+10  T 929  ☑ 929 \n",
            "Q 10+40   T 50   ☑ 50  \n",
            "Q 498+3   T 501  ☑ 501 \n",
            "Q 8+295   T 303  ☑ 303 \n",
            "Q 343+59  T 402  ☑ 402 \n",
            "Q 6+411   T 417  ☑ 417 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0106 - val_accuracy: 0.9978\n",
            "Q 608+69  T 677  ☑ 677 \n",
            "Q 288+62  T 350  ☑ 350 \n",
            "Q 724+623 T 1347 ☑ 1347\n",
            "Q 76+381  T 457  ☑ 457 \n",
            "Q 414+2   T 416  ☑ 416 \n",
            "Q 45+407  T 452  ☑ 452 \n",
            "Q 27+547  T 574  ☑ 574 \n",
            "Q 29+565  T 594  ☑ 594 \n",
            "Q 70+22   T 92   ☑ 92  \n",
            "Q 24+86   T 110  ☑ 110 \n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0234 - accuracy: 0.9934 - val_loss: 0.0080 - val_accuracy: 0.9984\n",
            "Q 122+71  T 193  ☑ 193 \n",
            "Q 39+53   T 92   ☑ 92  \n",
            "Q 129+1   T 130  ☑ 130 \n",
            "Q 794+93  T 887  ☑ 887 \n",
            "Q 485+505 T 990  ☑ 990 \n",
            "Q 522+5   T 527  ☑ 527 \n",
            "Q 445+282 T 727  ☑ 727 \n",
            "Q 771+18  T 789  ☑ 789 \n",
            "Q 141+68  T 209  ☑ 209 \n",
            "Q 472+3   T 475  ☑ 475 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0262 - accuracy: 0.9925 - val_loss: 0.0094 - val_accuracy: 0.9977\n",
            "Q 136+44  T 180  ☑ 180 \n",
            "Q 26+16   T 42   ☑ 42  \n",
            "Q 8+271   T 279  ☑ 279 \n",
            "Q 189+4   T 193  ☑ 193 \n",
            "Q 807+110 T 917  ☑ 917 \n",
            "Q 494+9   T 503  ☑ 503 \n",
            "Q 85+734  T 819  ☑ 819 \n",
            "Q 892+345 T 1237 ☑ 1237\n",
            "Q 631+421 T 1052 ☑ 1052\n",
            "Q 597+61  T 658  ☑ 658 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0185 - accuracy: 0.9956 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
            "Q 491+827 T 1318 ☑ 1318\n",
            "Q 933+42  T 975  ☑ 975 \n",
            "Q 479+46  T 525  ☑ 525 \n",
            "Q 347+85  T 432  ☑ 432 \n",
            "Q 975+7   T 982  ☑ 982 \n",
            "Q 619+278 T 897  ☑ 897 \n",
            "Q 751+6   T 757  ☑ 757 \n",
            "Q 98+35   T 133  ☑ 133 \n",
            "Q 471+91  T 562  ☑ 562 \n",
            "Q 76+87   T 163  ☑ 163 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
            "Q 268+39  T 307  ☑ 307 \n",
            "Q 61+269  T 330  ☑ 330 \n",
            "Q 932+69  T 1001 ☑ 1001\n",
            "Q 633+69  T 702  ☑ 702 \n",
            "Q 55+216  T 271  ☑ 271 \n",
            "Q 224+909 T 1133 ☑ 1133\n",
            "Q 516+75  T 591  ☑ 591 \n",
            "Q 211+60  T 271  ☑ 271 \n",
            "Q 29+569  T 598  ☑ 598 \n",
            "Q 55+769  T 824  ☑ 824 \n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.0211 - val_accuracy: 0.9937\n",
            "Q 167+732 T 899  ☑ 899 \n",
            "Q 954+8   T 962  ☑ 962 \n",
            "Q 99+585  T 684  ☑ 684 \n",
            "Q 885+402 T 1287 ☑ 1287\n",
            "Q 970+6   T 976  ☑ 976 \n",
            "Q 474+893 T 1367 ☑ 1367\n",
            "Q 462+98  T 560  ☑ 560 \n",
            "Q 657+393 T 1050 ☑ 1050\n",
            "Q 77+555  T 632  ☑ 632 \n",
            "Q 946+940 T 1886 ☑ 1886\n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0153 - accuracy: 0.9959 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
            "Q 82+31   T 113  ☑ 113 \n",
            "Q 78+731  T 809  ☑ 809 \n",
            "Q 258+18  T 276  ☑ 276 \n",
            "Q 334+76  T 410  ☑ 410 \n",
            "Q 99+29   T 128  ☑ 128 \n",
            "Q 651+223 T 874  ☑ 874 \n",
            "Q 394+882 T 1276 ☑ 1276\n",
            "Q 61+95   T 156  ☑ 156 \n",
            "Q 36+597  T 633  ☑ 633 \n",
            "Q 508+673 T 1181 ☑ 1181\n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 8s 6ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 0.0064 - val_accuracy: 0.9988\n",
            "Q 5+326   T 331  ☑ 331 \n",
            "Q 767+743 T 1510 ☑ 1510\n",
            "Q 886+663 T 1549 ☑ 1549\n",
            "Q 9+111   T 120  ☑ 120 \n",
            "Q 858+3   T 861  ☑ 861 \n",
            "Q 4+72    T 76   ☑ 76  \n",
            "Q 55+671  T 726  ☑ 726 \n",
            "Q 553+12  T 565  ☑ 565 \n",
            "Q 926+2   T 928  ☑ 928 \n",
            "Q 58+859  T 917  ☑ 917 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3AO_JLlo-Eu"
      },
      "source": [
        "대략 30 epoch 뒤에 99+% 정도의 validation 정확도를 보인다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx4wwMdOBGCg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}